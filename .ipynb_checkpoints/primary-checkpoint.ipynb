{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "470a814c",
   "metadata": {},
   "source": [
    "<h3>importing libraries</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17c5165a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8001de60",
   "metadata": {},
   "source": [
    "<h5>read data and explore it </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "631b5108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159256 entries, 0 to 159255\n",
      "Data columns (total 11 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   eyesight(left)    159256 non-null  float64\n",
      " 1   systolic          159256 non-null  int64  \n",
      " 2   serum creatinine  159256 non-null  float64\n",
      " 3   triglyceride      159256 non-null  int64  \n",
      " 4   Cholesterol       159256 non-null  int64  \n",
      " 5   AST               159256 non-null  int64  \n",
      " 6   height(cm)        159256 non-null  int64  \n",
      " 7   waist(cm)         159256 non-null  float64\n",
      " 8   age               159256 non-null  int64  \n",
      " 9   LDL               159256 non-null  int64  \n",
      " 10  smoking           159256 non-null  int64  \n",
      "dtypes: float64(3), int64(8)\n",
      "memory usage: 13.4 MB\n",
      "eyesight(left)      0\n",
      "systolic            0\n",
      "serum creatinine    0\n",
      "triglyceride        0\n",
      "Cholesterol         0\n",
      "AST                 0\n",
      "height(cm)          0\n",
      "waist(cm)           0\n",
      "age                 0\n",
      "LDL                 0\n",
      "smoking             0\n",
      "dtype: int64\n",
      "(159256, 11)\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(\"Your_data.csv\")\n",
    "data.drop(data.columns[0], axis=1,inplace=True)\n",
    "data.head(3)\n",
    "data.info()\n",
    "print(str(data.isnull().sum()))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87741e5",
   "metadata": {},
   "source": [
    "<h4> data split in train , test and validataion</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2465dc42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159256, 11)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X=data.drop('smoking', axis=1)\n",
    "Y = data['smoking']\n",
    "train_data, test_data = train_test_split(data, test_size=0.3, random_state=42, stratify=data['smoking'])\n",
    "X_train=train_data.drop(['smoking'],axis=1)\n",
    "Y_train=train_data['smoking']\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a2af2e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5413d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650d72d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08d42c6b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f95d140",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20422f33",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55aa1c37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cca4c7ff",
   "metadata": {},
   "source": [
    "<h3> remove outliers from train data by percentile</h3>\n",
    "<p> test age feature</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58cc3ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.0 20.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_threshold=train_data['age'].quantile(1)\n",
    "min_threshold=train_data['age'].quantile(0)\n",
    "print(max_threshold,min_threshold)\n",
    "#all ages are possible ages of smokers won't remove any"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d7e5f1",
   "metadata": {},
   "source": [
    "<p> test LDL feature</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73ccf0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202.0 42.0\n",
      "(111249, 11)\n"
     ]
    }
   ],
   "source": [
    "max_threshold = train_data['LDL'].quantile(0.999)\n",
    "min_threshold = train_data['LDL'].quantile(0.001)\n",
    "print(max_threshold,min_threshold)\n",
    "train_data = train_data[(train_data['LDL'] < max_threshold) & (train_data['LDL'] > min_threshold)]\n",
    "\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecdbc7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test AST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37841f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187.87679999995453 9.0\n",
      "(111221, 11)\n"
     ]
    }
   ],
   "source": [
    "max_threshold = train_data['AST'].quantile(0.9999)\n",
    "min_threshold = train_data['AST'].quantile(0.0001)\n",
    "print(max_threshold,min_threshold)\n",
    "train_data = train_data[(train_data['AST'] < max_threshold) & (train_data['AST'] > min_threshold)]\n",
    "\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c734284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.987799999998242 0.1122\n",
      "(111197, 11)\n"
     ]
    }
   ],
   "source": [
    "max_threshold = train_data['serum creatinine'].quantile(0.9999)\n",
    "min_threshold = train_data['serum creatinine'].quantile(0.0001)\n",
    "print(max_threshold,min_threshold)\n",
    "train_data = train_data[(train_data['serum creatinine'] < max_threshold) & (train_data['serum creatinine'] > min_threshold)]\n",
    "\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2543cb73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30fa59e6",
   "metadata": {},
   "source": [
    "<p> test chelosterol feature</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "011f5275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283.0 118.0\n",
      "(110963, 11)\n"
     ]
    }
   ],
   "source": [
    "max_threshold = train_data['Cholesterol'].quantile(0.999)\n",
    "min_threshold = train_data['Cholesterol'].quantile(0.001)\n",
    "print(max_threshold,min_threshold)\n",
    "train_data = train_data[(train_data['Cholesterol'] < max_threshold) & (train_data['Cholesterol'] > min_threshold)]\n",
    "\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61323198",
   "metadata": {},
   "source": [
    "<p>test systolic feature</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea6729d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170.0 90.0\n",
      "(110300, 11)\n"
     ]
    }
   ],
   "source": [
    "max_threshold = train_data['systolic'].quantile(0.999)\n",
    "min_threshold = train_data['systolic'].quantile(0.001)\n",
    "print(max_threshold,min_threshold)\n",
    "train_data = train_data[(train_data['systolic'] < max_threshold) & (train_data['systolic'] > min_threshold)]\n",
    "\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6ad985",
   "metadata": {},
   "source": [
    "test height feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9976329d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185.0 140.0\n",
      "(108906, 11)\n"
     ]
    }
   ],
   "source": [
    "max_threshold = train_data['height(cm)'].quantile(0.999)\n",
    "min_threshold = train_data['height(cm)'].quantile(0.001)\n",
    "print(max_threshold,min_threshold)\n",
    "train_data = train_data[(train_data['height(cm)'] < max_threshold) & (train_data['height(cm)'] > min_threshold)]\n",
    "\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f691f4b",
   "metadata": {},
   "source": [
    "<h3>z score normalization to remove outliers</h3>\n",
    "<p>  is suited for triglyceride distribution</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6a5709a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(107774, 11)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "z_scores = zscore(train_data['triglyceride'])\n",
    "z_score_threshold = 3\n",
    "outliers = np.abs(z_scores) > z_score_threshold\n",
    "\n",
    "train_data = train_data[~outliers]\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "339dc57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(107494, 11)\n"
     ]
    }
   ],
   "source": [
    "#waist\n",
    "z_scores = zscore(train_data['waist(cm)'])\n",
    "z_score_threshold = 3\n",
    "outliers = np.abs(z_scores) > z_score_threshold\n",
    "\n",
    "train_data = train_data[~outliers]\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "862729df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(107401, 11)\n"
     ]
    }
   ],
   "source": [
    "#eyesight(left)\n",
    "z_scores = zscore(train_data['eyesight(left)'])\n",
    "z_score_threshold = 3\n",
    "outliers = np.abs(z_scores) > z_score_threshold\n",
    "\n",
    "train_data = train_data[~outliers]\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a36471",
   "metadata": {},
   "source": [
    "<h3>splitting train,test,validate data into x and y </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e30e30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train=train_data.drop(['smoking'],axis=1)\n",
    "Y_train=train_data['smoking']\n",
    "validation,test=train_test_split(test_data, test_size=0.5, random_state=42, stratify=test_data['smoking'])\n",
    "X_valid=validation.drop(['smoking'],axis=1)\n",
    "Y_valid=validation['smoking']\n",
    "X_test=test.drop(['smoking'],axis=1)\n",
    "Y_test=test['smoking']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70485b7d",
   "metadata": {},
   "source": [
    "<h3>data normalization</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "50faccd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(131290, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(131290,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizer=StandardScaler()\n",
    "X_train=normalizer.fit_transform(X_train)\n",
    "X_test = normalizer.transform(X_test)\n",
    "X_valid=normalizer.transform(X_valid)\n",
    "X = np.vstack((X_train, X_test))\n",
    "print(X.shape)\n",
    "Y = np.concatenate((Y_train.values, Y_test.values))\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "098e843b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smoking\n",
       "0    60866\n",
       "1    46535\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1b78cb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train using stand alone model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ce03ffc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.67107167, 0.66646355, 0.6684439 , 0.66497829, 0.66859624])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "scores = cross_val_score(DecisionTreeClassifier(), X, Y, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "94948fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6679107319674005"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cc533b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train using Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "647a760a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7396672284243163"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bag_model = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(), \n",
    "    n_estimators=100, \n",
    "    max_samples=0.8, \n",
    "    oob_score=True,\n",
    "    random_state=0\n",
    ")\n",
    "bag_model.fit(X_train, Y_train)\n",
    "bag_model.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "85adfddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7396182183523108"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_model.score(X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ed655bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score= 0.7398255137289225\n",
      "validation score= 0.7390321500334897\n"
     ]
    }
   ],
   "source": [
    "#try to drop serum ceratine feature because it has low variance\n",
    "X_train=train_data.drop(['serum creatinine'],axis=1)\n",
    "X_train=train_data.drop(['smoking'],axis=1)\n",
    "X_valid=validation.drop(['serum creatinine'],axis=1)\n",
    "X_valid=validation.drop(['smoking'],axis=1)\n",
    "bag_model = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(), \n",
    "    n_estimators=100, \n",
    "    max_samples=0.8, \n",
    "    oob_score=True,\n",
    "    random_state=0\n",
    ")\n",
    "bag_model.fit(X_train, Y_train)\n",
    "print(\"train score= \"+str(bag_model.oob_score_))\n",
    "print(\"validation score= \"+str(bag_model.score(X_valid, Y_valid)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e17c0d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score= 0.7395741194216069\n",
      "validation score= 0.737399531145345\n"
     ]
    }
   ],
   "source": [
    "#try to drop LDL because it has high correlation with chelosterol\n",
    "X_train=train_data.drop(['LDL'],axis=1)\n",
    "X_train=train_data.drop(['smoking'],axis=1)\n",
    "X_valid=validation.drop(['LDL'],axis=1)\n",
    "X_valid=validation.drop(['smoking'],axis=1)\n",
    "bag_model1 = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(), \n",
    "    n_estimators=100, \n",
    "    max_samples=0.8, \n",
    "    oob_score=True,\n",
    "    random_state=0\n",
    ")\n",
    "bag_model1.fit(X_train, Y_train)\n",
    "print(\"train score= \"+str(bag_model1.oob_score_))\n",
    "print(\"validation score= \"+str(bag_model1.score(X_valid, Y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "14ff91db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score= 0.7395741194216069\n",
      "validation score= 0.737399531145345\n"
     ]
    }
   ],
   "source": [
    "train_data['sysheight']=train_data['systolic']*train_data['height(cm)']\n",
    "validation['sysheight']=validation['systolic']*validation['height(cm)']\n",
    "X_train=train_data.drop(['smoking'],axis=1)\n",
    "X_valid=validation.drop(['smoking'],axis=1)\n",
    "bag_model2 = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(), \n",
    "    n_estimators=100, \n",
    "    max_samples=0.8, \n",
    "    oob_score=True,\n",
    "    random_state=0\n",
    ")\n",
    "bag_model2.fit(X_train, Y_train)\n",
    "print(\"train score= \"+str(bag_model2.oob_score_))\n",
    "print(\"validation score= \"+str(bag_model2.score(X_valid, Y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef285fab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "056ea41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 1 : 0.7409578030810449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 2 : 0.7093938379102478\n"
     ]
    }
   ],
   "source": [
    "X_train=train_data.drop(['smoking'],axis=1)\n",
    "X_valid=validation.drop(['smoking'],axis=1)\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import metrics\n",
    "Adamodel = AdaBoostClassifier(n_estimators=100 ,learning_rate=1)\n",
    "model = Adamodel.fit(X_train,Y_train)\n",
    "y_pred = model.predict(X_valid)\n",
    "print(\"Accuracy 1 :\",metrics.accuracy_score(Y_valid,y_pred)) \n",
    "# -----------------------------------------------------------\n",
    "# using logisticRegression \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "logisticModel = LogisticRegression()\n",
    "Adamodel_2 = AdaBoostClassifier(n_estimators=50 ,base_estimator=logisticModel,learning_rate=1)\n",
    "model_2 = Adamodel_2.fit(X_train,Y_train)\n",
    "y_pred_2 = model_2.predict(X_valid)\n",
    "print(\"Accuracy 2 :\",metrics.accuracy_score(Y_valid,y_pred_2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "56c9c8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 1 : 0.5626438946795597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 2 : 0.5626438946795597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#try to drop serum ceratine feature because it has low variance\n",
    "X_train=train_data.drop(['serum creatinine'],axis=1)\n",
    "X_train=train_data.drop(['smoking'],axis=1)\n",
    "X_valid=validation.drop(['serum creatinine'],axis=1)\n",
    "X_valid=validation.drop(['smoking'],axis=1)\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import metrics\n",
    "Adamodel = AdaBoostClassifier(n_estimators=100 ,learning_rate=1)\n",
    "model = Adamodel.fit(X_train,Y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy 1 :\",metrics.accuracy_score(Y_test,y_pred)) \n",
    "# -----------------------------------------------------------\n",
    "# using logisticRegression \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "logisticModel = LogisticRegression()\n",
    "Adamodel_2 = AdaBoostClassifier(n_estimators=50 ,base_estimator=logisticModel,learning_rate=1)\n",
    "model_2 = Adamodel_2.fit(X_train,Y_train)\n",
    "y_pred_2 = model_2.predict(X_test)\n",
    "print(\"Accuracy 2 :\",metrics.accuracy_score(Y_test,y_pred_2)) \n",
    "# ada boast model needs the features with low variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9270870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train using Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c00e1284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  : 0.7429253181513731\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "randomForest = RandomForestClassifier(n_estimators= 100)\n",
    "randomForestModel = randomForest.fit(X_train,Y_train)\n",
    "y_pred_0 = randomForestModel.predict(X_valid)\n",
    "# randomForestModel.oob_score_\n",
    "print(\"Accuracy  :\",metrics.accuracy_score(Y_valid,y_pred_0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f1819df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  : 0.7441393168117884\n"
     ]
    }
   ],
   "source": [
    "# try adding another feature to random forest model\n",
    "train_data['sysheight']=train_data['systolic']*train_data['height(cm)']\n",
    "validation['sysheight']=validation['systolic']*validation['height(cm)']\n",
    "X_train=train_data.drop(['smoking'],axis=1)\n",
    "X_valid=validation.drop(['smoking'],axis=1)\n",
    "randomForest = RandomForestClassifier(n_estimators= 100)\n",
    "randomForestModel = randomForest.fit(X_train,Y_train)\n",
    "y_pred_0 = randomForestModel.predict(X_valid)\n",
    "# randomForestModel.oob_score_\n",
    "print(\"Accuracy  :\",metrics.accuracy_score(Y_valid,y_pred_0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c5ba28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inert another"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d11aaf",
   "metadata": {},
   "source": [
    "<h1>GRIDSEARCH</h1>\n",
    "<h3>GRIDSERACH FOR BaggingClassifier</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4362c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131a163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "result = GridSearchCV(\n",
    "        BaggingClassifier(),\n",
    "        {\n",
    "            'estimator': [DecisionTreeClassifier()],\n",
    "            'n_estimators': [10, 50, 100],\n",
    "            'max_samples': [0.3, 0.5, 0.8, 0.9],\n",
    "            'oob_score': [True, False],\n",
    "            'random_state': [0]\n",
    "        },\n",
    "    cv=5,\n",
    "    return_train_score=False\n",
    ")\n",
    "\n",
    "result.fit(X,y)\n",
    "result.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fe8089",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(result.cv_results_)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cef830",
   "metadata": {},
   "outputs": [],
   "source": [
    "df [['param_n_estimators','params','mean_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dba70d2",
   "metadata": {},
   "source": [
    "<h3>Random GridSearch for Bagging</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee728ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "result = RandomizedSearchCV(\n",
    "        BaggingClassifier(),\n",
    "        {\n",
    "            'estimator': [DecisionTreeClassifier()],\n",
    "            'n_estimators': [10, 50, 100],\n",
    "            'max_samples': [0.3, 0.5, 0.8, 0.9],\n",
    "            'oob_score': [True, False],\n",
    "            'random_state': [0]\n",
    "        },\n",
    "    cv=5,\n",
    "    return_train_score=False\n",
    ")\n",
    "\n",
    "result.fit(X,y)\n",
    "pd.DataFrame(result.cv_results_)[['param_n_estimators','params','mean_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce28993",
   "metadata": {},
   "source": [
    "<h3>GRIDSERACH FOR RandomForestClassifier</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4128e730",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "result = GridSearchCV(\n",
    "    RandomForestClassifier(), {\n",
    "        'n_estimators': [1,5,10,50]\n",
    "    },\n",
    "    cv = 5,return_train_score = False,n_iter =2\n",
    ")\n",
    "\n",
    "result.fit(X,y)\n",
    "result.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e58b461",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(result.cv_results_)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09f1679",
   "metadata": {},
   "source": [
    "<h3>picking columns from tables to see score</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2556f769",
   "metadata": {},
   "outputs": [],
   "source": [
    "df [['param_n_estimators','params','mean_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecec75cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "<h2>getting best score</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8e2329",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e889f1",
   "metadata": {},
   "source": [
    "<h3>getting best parameters</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556a6095",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187259f9",
   "metadata": {},
   "source": [
    "<h2>RANDOMIZED GridSearch</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154621e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "result = RandomizedSearchCV(\n",
    "    RandomForestClassifier(), {\n",
    "        'n_estimators': [1,5,10,50]\n",
    "    },\n",
    "    cv = 5,return_train_score = False,n_iter =2  #give number of combinations of features\n",
    ")\n",
    "\n",
    "result.fit(X,y)\n",
    "pd.DataFrame(result.cv_results_)[['param_n_estimators','params','mean_test_score']]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
