{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "470a814c",
   "metadata": {},
   "source": [
    "<h3>importing libraries</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17c5165a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8001de60",
   "metadata": {},
   "source": [
    "<h5>read data and explore it </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "631b5108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159256 entries, 0 to 159255\n",
      "Data columns (total 11 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   eyesight(left)    159256 non-null  float64\n",
      " 1   systolic          159256 non-null  int64  \n",
      " 2   serum creatinine  159256 non-null  float64\n",
      " 3   triglyceride      159256 non-null  int64  \n",
      " 4   Cholesterol       159256 non-null  int64  \n",
      " 5   AST               159256 non-null  int64  \n",
      " 6   height(cm)        159256 non-null  int64  \n",
      " 7   waist(cm)         159256 non-null  float64\n",
      " 8   age               159256 non-null  int64  \n",
      " 9   LDL               159256 non-null  int64  \n",
      " 10  smoking           159256 non-null  int64  \n",
      "dtypes: float64(3), int64(8)\n",
      "memory usage: 13.4 MB\n",
      "eyesight(left)      0\n",
      "systolic            0\n",
      "serum creatinine    0\n",
      "triglyceride        0\n",
      "Cholesterol         0\n",
      "AST                 0\n",
      "height(cm)          0\n",
      "waist(cm)           0\n",
      "age                 0\n",
      "LDL                 0\n",
      "smoking             0\n",
      "dtype: int64\n",
      "(159256, 11)\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(\"Your_data.csv\")\n",
    "data.drop(data.columns[0], axis=1,inplace=True)\n",
    "data.head(3)\n",
    "data.info()\n",
    "print(str(data.isnull().sum()))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87741e5",
   "metadata": {},
   "source": [
    "<h4> data split in train , test and validataion</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2465dc42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159256, 11)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X=data.drop('smoking', axis=1)\n",
    "Y = data['smoking']\n",
    "train_data, test_data = train_test_split(data, test_size=0.3, random_state=42, stratify=data['smoking'])\n",
    "X_train=train_data.drop(['smoking'],axis=1)\n",
    "Y_train=train_data['smoking']\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca4c7ff",
   "metadata": {},
   "source": [
    "<h3> remove outliers from train data by percentile</h3>\n",
    "<p> test age feature</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58cc3ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.0 20.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_threshold=train_data['age'].quantile(1)\n",
    "min_threshold=train_data['age'].quantile(0)\n",
    "print(max_threshold,min_threshold)\n",
    "#all ages are possible ages of smokers won't remove any"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d7e5f1",
   "metadata": {},
   "source": [
    "<p> test LDL feature</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73ccf0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202.0 42.0\n",
      "(111249, 11)\n"
     ]
    }
   ],
   "source": [
    "max_threshold = train_data['LDL'].quantile(0.999)\n",
    "min_threshold = train_data['LDL'].quantile(0.001)\n",
    "print(max_threshold,min_threshold)\n",
    "train_data = train_data[(train_data['LDL'] < max_threshold) & (train_data['LDL'] > min_threshold)]\n",
    "\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecdbc7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test AST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37841f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187.87679999995453 9.0\n",
      "(111221, 11)\n"
     ]
    }
   ],
   "source": [
    "max_threshold = train_data['AST'].quantile(0.9999)\n",
    "min_threshold = train_data['AST'].quantile(0.0001)\n",
    "print(max_threshold,min_threshold)\n",
    "train_data = train_data[(train_data['AST'] < max_threshold) & (train_data['AST'] > min_threshold)]\n",
    "\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c734284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.987799999998242 0.1122\n",
      "(111197, 11)\n"
     ]
    }
   ],
   "source": [
    "max_threshold = train_data['serum creatinine'].quantile(0.9999)\n",
    "min_threshold = train_data['serum creatinine'].quantile(0.0001)\n",
    "print(max_threshold,min_threshold)\n",
    "train_data = train_data[(train_data['serum creatinine'] < max_threshold) & (train_data['serum creatinine'] > min_threshold)]\n",
    "\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2543cb73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30fa59e6",
   "metadata": {},
   "source": [
    "<p> test chelosterol feature</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "011f5275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283.0 118.0\n",
      "(110963, 11)\n"
     ]
    }
   ],
   "source": [
    "max_threshold = train_data['Cholesterol'].quantile(0.999)\n",
    "min_threshold = train_data['Cholesterol'].quantile(0.001)\n",
    "print(max_threshold,min_threshold)\n",
    "train_data = train_data[(train_data['Cholesterol'] < max_threshold) & (train_data['Cholesterol'] > min_threshold)]\n",
    "\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61323198",
   "metadata": {},
   "source": [
    "<p>test systolic feature</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea6729d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170.0 90.0\n",
      "(110300, 11)\n"
     ]
    }
   ],
   "source": [
    "max_threshold = train_data['systolic'].quantile(0.999)\n",
    "min_threshold = train_data['systolic'].quantile(0.001)\n",
    "print(max_threshold,min_threshold)\n",
    "train_data = train_data[(train_data['systolic'] < max_threshold) & (train_data['systolic'] > min_threshold)]\n",
    "\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6ad985",
   "metadata": {},
   "source": [
    "test height feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9976329d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185.0 140.0\n",
      "(108906, 11)\n"
     ]
    }
   ],
   "source": [
    "max_threshold = train_data['height(cm)'].quantile(0.999)\n",
    "min_threshold = train_data['height(cm)'].quantile(0.001)\n",
    "print(max_threshold,min_threshold)\n",
    "train_data = train_data[(train_data['height(cm)'] < max_threshold) & (train_data['height(cm)'] > min_threshold)]\n",
    "\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f691f4b",
   "metadata": {},
   "source": [
    "<h3>z score normalization to remove outliers</h3>\n",
    "<p>  is suited for triglyceride distribution</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6a5709a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(107774, 11)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "z_scores = zscore(train_data['triglyceride'])\n",
    "z_score_threshold = 3\n",
    "outliers = np.abs(z_scores) > z_score_threshold\n",
    "\n",
    "train_data = train_data[~outliers]\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "339dc57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(107494, 11)\n"
     ]
    }
   ],
   "source": [
    "#waist\n",
    "z_scores = zscore(train_data['waist(cm)'])\n",
    "z_score_threshold = 3\n",
    "outliers = np.abs(z_scores) > z_score_threshold\n",
    "\n",
    "train_data = train_data[~outliers]\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "862729df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(107401, 11)\n"
     ]
    }
   ],
   "source": [
    "#eyesight(left)\n",
    "z_scores = zscore(train_data['eyesight(left)'])\n",
    "z_score_threshold = 3\n",
    "outliers = np.abs(z_scores) > z_score_threshold\n",
    "\n",
    "train_data = train_data[~outliers]\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a36471",
   "metadata": {},
   "source": [
    "<h3>splitting train,test,validate data into x and y </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e30e30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train=train_data.drop(['smoking'],axis=1)\n",
    "Y_train=train_data['smoking']\n",
    "validation,test=train_test_split(test_data, test_size=0.5, random_state=42, stratify=test_data['smoking'])\n",
    "X_valid=validation.drop(['smoking'],axis=1)\n",
    "Y_valid=validation['smoking']\n",
    "X_test=test.drop(['smoking'],axis=1)\n",
    "Y_test=test['smoking']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70485b7d",
   "metadata": {},
   "source": [
    "<h3>data normalization</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50faccd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(131290, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(131290,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizer=StandardScaler()\n",
    "X_train=normalizer.fit_transform(X_train)\n",
    "X_test = normalizer.transform(X_test)\n",
    "X_valid=normalizer.transform(X_valid)\n",
    "X = np.vstack((X_train, X_test))\n",
    "print(X.shape)\n",
    "Y = np.concatenate((Y_train.values, Y_test.values))\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "098e843b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smoking\n",
       "0    60866\n",
       "1    46535\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b78cb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train using stand alone model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce03ffc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.66966258, 0.66322645, 0.67069084, 0.66269327, 0.66688247])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "scores = cross_val_score(DecisionTreeClassifier(), X, Y, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94948fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666311219437886"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc533b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train using Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "647a760a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7396672284243163"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bag_model = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(), \n",
    "    n_estimators=100, \n",
    "    max_samples=0.8, \n",
    "    oob_score=True,\n",
    "    random_state=0\n",
    ")\n",
    "bag_model.fit(X_train, Y_train)\n",
    "bag_model.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85adfddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7396182183523108"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_model.score(X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed655bd8",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 13\u001b[0m\n\u001b[0;32m      5\u001b[0m X_valid\u001b[38;5;241m=\u001b[39mvalidation\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msmoking\u001b[39m\u001b[38;5;124m'\u001b[39m],axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      6\u001b[0m bag_model \u001b[38;5;241m=\u001b[39m BaggingClassifier(\n\u001b[0;32m      7\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mDecisionTreeClassifier(), \n\u001b[0;32m      8\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     12\u001b[0m )\n\u001b[1;32m---> 13\u001b[0m bag_model\u001b[38;5;241m.\u001b[39mfit(X_train, Y_train)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain score= \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(bag_model\u001b[38;5;241m.\u001b[39moob_score_))\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation score= \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(bag_model\u001b[38;5;241m.\u001b[39mscore(X_valid, Y_valid)))\n",
      "File \u001b[1;32md:\\anaconda\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_bagging.py:338\u001b[0m, in \u001b[0;36mBaseBagging.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;66;03m# Convert data (X is required to be 2d and indexable)\u001b[39;00m\n\u001b[0;32m    330\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    331\u001b[0m     X,\n\u001b[0;32m    332\u001b[0m     y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    336\u001b[0m     multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    337\u001b[0m )\n\u001b[1;32m--> 338\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X, y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_samples, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[1;32md:\\anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_bagging.py:473\u001b[0m, in \u001b[0;36mBaseBagging._fit\u001b[1;34m(self, X, y, max_samples, max_depth, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    470\u001b[0m seeds \u001b[38;5;241m=\u001b[39m random_state\u001b[38;5;241m.\u001b[39mrandint(MAX_INT, size\u001b[38;5;241m=\u001b[39mn_more_estimators)\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_seeds \u001b[38;5;241m=\u001b[39m seeds\n\u001b[1;32m--> 473\u001b[0m all_results \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[0;32m    474\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parallel_args()\n\u001b[0;32m    475\u001b[0m )(\n\u001b[0;32m    476\u001b[0m     delayed(_parallel_build_estimators)(\n\u001b[0;32m    477\u001b[0m         n_estimators[i],\n\u001b[0;32m    478\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    479\u001b[0m         X,\n\u001b[0;32m    480\u001b[0m         y,\n\u001b[0;32m    481\u001b[0m         sample_weight,\n\u001b[0;32m    482\u001b[0m         seeds[starts[i] : starts[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]],\n\u001b[0;32m    483\u001b[0m         total_n_estimators,\n\u001b[0;32m    484\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    485\u001b[0m         check_input\u001b[38;5;241m=\u001b[39mcheck_input,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[0;32m    487\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_jobs)\n\u001b[0;32m    488\u001b[0m )\n\u001b[0;32m    490\u001b[0m \u001b[38;5;66;03m# Reduce\u001b[39;00m\n\u001b[0;32m    491\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m    492\u001b[0m     itertools\u001b[38;5;241m.\u001b[39mchain\u001b[38;5;241m.\u001b[39mfrom_iterable(t[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m all_results)\n\u001b[0;32m    493\u001b[0m )\n",
      "File \u001b[1;32md:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32md:\\anaconda\\Lib\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32md:\\anaconda\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32md:\\anaconda\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32md:\\anaconda\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[1;32md:\\anaconda\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32md:\\anaconda\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32md:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_bagging.py:141\u001b[0m, in \u001b[0;36m_parallel_build_estimators\u001b[1;34m(n_estimators, ensemble, X, y, sample_weight, seeds, total_n_estimators, verbose, check_input)\u001b[0m\n\u001b[0;32m    138\u001b[0m         curr_sample_weight[not_indices_mask] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    140\u001b[0m     X_ \u001b[38;5;241m=\u001b[39m X[:, features] \u001b[38;5;28;01mif\u001b[39;00m requires_feature_indexing \u001b[38;5;28;01melse\u001b[39;00m X\n\u001b[1;32m--> 141\u001b[0m     estimator_fit(X_, y, sample_weight\u001b[38;5;241m=\u001b[39mcurr_sample_weight)\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m     X_ \u001b[38;5;241m=\u001b[39m X[indices][:, features] \u001b[38;5;28;01mif\u001b[39;00m requires_feature_indexing \u001b[38;5;28;01melse\u001b[39;00m X[indices]\n",
      "File \u001b[1;32md:\\anaconda\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\anaconda\\Lib\\site-packages\\sklearn\\tree\\_classes.py:959\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    929\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    930\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    931\u001b[0m \n\u001b[0;32m    932\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 959\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    960\u001b[0m         X,\n\u001b[0;32m    961\u001b[0m         y,\n\u001b[0;32m    962\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    963\u001b[0m         check_input\u001b[38;5;241m=\u001b[39mcheck_input,\n\u001b[0;32m    964\u001b[0m     )\n\u001b[0;32m    965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32md:\\anaconda\\Lib\\site-packages\\sklearn\\tree\\_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    434\u001b[0m         splitter,\n\u001b[0;32m    435\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    441\u001b[0m     )\n\u001b[1;32m--> 443\u001b[0m builder\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#try to drop serum ceratine feature because it has low variance\n",
    "X_train=train_data.drop(['serum creatinine'],axis=1)\n",
    "X_train=train_data.drop(['smoking'],axis=1)\n",
    "X_valid=validation.drop(['serum creatinine'],axis=1)\n",
    "X_valid=validation.drop(['smoking'],axis=1)\n",
    "bag_model = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(), \n",
    "    n_estimators=100, \n",
    "    max_samples=0.8, \n",
    "    oob_score=True,\n",
    "    random_state=0\n",
    ")\n",
    "bag_model.fit(X_train, Y_train)\n",
    "print(\"train score= \"+str(bag_model.oob_score_))\n",
    "print(\"validation score= \"+str(bag_model.score(X_valid, Y_valid)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17c0d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score= 0.7398255137289225\n",
      "validation score= 0.7390321500334897\n"
     ]
    }
   ],
   "source": [
    "#try to drop LDL because it has high correlation with chelosterol\n",
    "X_train=train_data.drop(['LDL'],axis=1)\n",
    "X_train=train_data.drop(['smoking'],axis=1)\n",
    "X_valid=validation.drop(['LDL'],axis=1)\n",
    "X_valid=validation.drop(['smoking'],axis=1)\n",
    "bag_model1 = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(), \n",
    "    n_estimators=100, \n",
    "    max_samples=0.8, \n",
    "    oob_score=True,\n",
    "    random_state=0\n",
    ")\n",
    "bag_model1.fit(X_train, Y_train)\n",
    "print(\"train score= \"+str(bag_model1.oob_score_))\n",
    "print(\"validation score= \"+str(bag_model1.score(X_valid, Y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ff91db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score= 0.7395741194216069\n",
      "validation score= 0.737399531145345\n"
     ]
    }
   ],
   "source": [
    "train_data['sysheight']=train_data['systolic']*train_data['height(cm)']\n",
    "validation['sysheight']=validation['systolic']*validation['height(cm)']\n",
    "X_train=train_data.drop(['smoking'],axis=1)\n",
    "X_valid=validation.drop(['smoking'],axis=1)\n",
    "bag_model2 = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(), \n",
    "    n_estimators=100, \n",
    "    max_samples=0.8, \n",
    "    oob_score=True,\n",
    "    random_state=0\n",
    ")\n",
    "bag_model2.fit(X_train, Y_train)\n",
    "print(\"train score= \"+str(bag_model2.oob_score_))\n",
    "print(\"validation score= \"+str(bag_model2.score(X_valid, Y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef285fab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056ea41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 1 : 0.740162424648359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 2 : 0.7094775619557937\n"
     ]
    }
   ],
   "source": [
    "X_train=train_data.drop(['smoking'],axis=1)\n",
    "X_valid=validation.drop(['smoking'],axis=1)\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import metrics\n",
    "Adamodel = AdaBoostClassifier(n_estimators=100 ,learning_rate=1)\n",
    "model = Adamodel.fit(X_train,Y_train)\n",
    "y_pred = model.predict(X_valid)\n",
    "print(\"Accuracy 1 :\",metrics.accuracy_score(Y_valid,y_pred)) \n",
    "# -----------------------------------------------------------\n",
    "# using logisticRegression \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "logisticModel = LogisticRegression()\n",
    "Adamodel_2 = AdaBoostClassifier(n_estimators=50 ,base_estimator=logisticModel,learning_rate=1)\n",
    "model_2 = Adamodel_2.fit(X_train,Y_train)\n",
    "y_pred_2 = model_2.predict(X_valid)\n",
    "print(\"Accuracy 2 :\",metrics.accuracy_score(Y_valid,y_pred_2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c9c8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 10 features, but AdaBoostClassifier is expecting 11 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m Adamodel \u001b[38;5;241m=\u001b[39m AdaBoostClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m ,learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m Adamodel\u001b[38;5;241m.\u001b[39mfit(X_train,Y_train)\n\u001b[1;32m---> 10\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy 1 :\u001b[39m\u001b[38;5;124m\"\u001b[39m,metrics\u001b[38;5;241m.\u001b[39maccuracy_score(Y_test,y_pred)) \n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# -----------------------------------------------------------\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# using logisticRegression \u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:710\u001b[0m, in \u001b[0;36mAdaBoostClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    693\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    694\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Predict classes for X.\u001b[39;00m\n\u001b[0;32m    695\u001b[0m \n\u001b[0;32m    696\u001b[0m \u001b[38;5;124;03m    The predicted class of an input sample is computed as the weighted mean\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    708\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 710\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X)\n\u001b[0;32m    712\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    713\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(pred \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32md:\\anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:771\u001b[0m, in \u001b[0;36mAdaBoostClassifier.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    752\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute the decision function of ``X``.\u001b[39;00m\n\u001b[0;32m    753\u001b[0m \n\u001b[0;32m    754\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    768\u001b[0m \u001b[38;5;124;03m    class in ``classes_``, respectively.\u001b[39;00m\n\u001b[0;32m    769\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    770\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 771\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X(X)\n\u001b[0;32m    773\u001b[0m n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_\n\u001b[0;32m    774\u001b[0m classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[:, np\u001b[38;5;241m.\u001b[39mnewaxis]\n",
      "File \u001b[1;32md:\\anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:101\u001b[0m, in \u001b[0;36mBaseWeightBoosting._check_X\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_X\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;66;03m# Only called to validate X in non-fit methods, therefore reset=False\u001b[39;00m\n\u001b[1;32m--> 101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    102\u001b[0m         X,\n\u001b[0;32m    103\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    104\u001b[0m         ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    105\u001b[0m         allow_nd\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    106\u001b[0m         dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    107\u001b[0m         reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    108\u001b[0m     )\n",
      "File \u001b[1;32md:\\anaconda\\Lib\\site-packages\\sklearn\\base.py:625\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    622\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 625\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32md:\\anaconda\\Lib\\site-packages\\sklearn\\base.py:414\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    416\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    417\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 10 features, but AdaBoostClassifier is expecting 11 features as input."
     ]
    }
   ],
   "source": [
    "#try to drop serum ceratine feature because it has low variance\n",
    "X_train=train_data.drop(['serum creatinine'],axis=1)\n",
    "X_train=train_data.drop(['smoking'],axis=1)\n",
    "X_valid=validation.drop(['serum creatinine'],axis=1)\n",
    "X_valid=validation.drop(['smoking'],axis=1)\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import metrics\n",
    "Adamodel = AdaBoostClassifier(n_estimators=100 ,learning_rate=1)\n",
    "model = Adamodel.fit(X_train,Y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy 1 :\",metrics.accuracy_score(Y_test,y_pred)) \n",
    "# -----------------------------------------------------------\n",
    "# using logisticRegression \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "logisticModel = LogisticRegression()\n",
    "Adamodel_2 = AdaBoostClassifier(n_estimators=50 ,base_estimator=logisticModel,learning_rate=1)\n",
    "model_2 = Adamodel_2.fit(X_train,Y_train)\n",
    "y_pred_2 = model_2.predict(X_test)\n",
    "print(\"Accuracy 2 :\",metrics.accuracy_score(Y_test,y_pred_2)) \n",
    "# ada boast model needs the features with low variation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84390797",
   "metadata": {},
   "source": [
    "# Train using Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00e1284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  : 0.7415020093770931\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "randomForest = RandomForestClassifier(n_estimators= 100)\n",
    "randomForestModel = randomForest.fit(X_train,Y_train)\n",
    "y_pred_0 = randomForestModel.predict(X_valid)\n",
    "# randomForestModel.oob_score_\n",
    "print(\"Accuracy  :\",metrics.accuracy_score(Y_valid,y_pred_0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1819df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  : 0.743009042196919\n"
     ]
    }
   ],
   "source": [
    "# try adding another feature to random forest model\n",
    "train_data['sysheight']=train_data['systolic']*train_data['height(cm)']\n",
    "validation['sysheight']=validation['systolic']*validation['height(cm)']\n",
    "X_train=train_data.drop(['smoking'],axis=1)\n",
    "X_valid=validation.drop(['smoking'],axis=1)\n",
    "randomForest = RandomForestClassifier(n_estimators= 100)\n",
    "randomForestModel = randomForest.fit(X_train,Y_train)\n",
    "y_pred_0 = randomForestModel.predict(X_valid)\n",
    "# randomForestModel.oob_score_\n",
    "print(\"Accuracy  :\",metrics.accuracy_score(Y_valid,y_pred_0)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d11aaf",
   "metadata": {},
   "source": [
    "<h1>GRIDSEARCH</h1>\n",
    "<h3>GRIDSERACH FOR BaggingClassifier</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "131a163b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 2.67829361,  2.25420461, 11.68784604, 10.56061234, 20.20408807,\n",
       "        17.031673  ,  3.00222826,  2.61858377, 14.16221762, 12.83734636,\n",
       "        27.95311847, 28.45090375,  3.60537753,  3.60387721, 19.72191372,\n",
       "        17.05202713, 41.83095465, 45.2688983 ,  3.78847785,  5.04969516,\n",
       "        25.77890387, 27.32422919, 44.60938458, 36.73508558]),\n",
       " 'std_fit_time': array([0.42178848, 0.17189954, 0.74036546, 0.81753671, 1.35200841,\n",
       "        0.63335197, 0.24192639, 0.10785551, 1.21751068, 0.76630562,\n",
       "        1.78650486, 0.90405713, 0.21247035, 0.18976237, 1.12573419,\n",
       "        0.25706661, 2.84412506, 2.65955212, 0.08326741, 0.88979024,\n",
       "        2.85419659, 1.69098691, 2.03565115, 3.61336503]),\n",
       " 'mean_score_time': array([0.04359536, 0.0556448 , 0.22944798, 0.18549623, 0.30615096,\n",
       "        0.31578541, 0.04112267, 0.04179211, 0.16748891, 0.16623373,\n",
       "        0.37665868, 0.38294926, 0.04149928, 0.0514854 , 0.19670038,\n",
       "        0.16171913, 0.54123392, 0.54841547, 0.04047308, 0.06833882,\n",
       "        0.25681233, 0.19353905, 0.28398533, 0.17366238]),\n",
       " 'std_score_time': array([0.00437854, 0.02074128, 0.05431618, 0.04054315, 0.01155071,\n",
       "        0.0454252 , 0.00752984, 0.00335575, 0.01524756, 0.01319501,\n",
       "        0.0920583 , 0.05030941, 0.00863396, 0.02092828, 0.04289168,\n",
       "        0.00396829, 0.09983824, 0.18498755, 0.00287361, 0.02188664,\n",
       "        0.07828791, 0.03240375, 0.03153297, 0.04708092]),\n",
       " 'param_estimator': masked_array(data=[DecisionTreeClassifier(), DecisionTreeClassifier(),\n",
       "                    DecisionTreeClassifier(), DecisionTreeClassifier(),\n",
       "                    DecisionTreeClassifier(), DecisionTreeClassifier(),\n",
       "                    DecisionTreeClassifier(), DecisionTreeClassifier(),\n",
       "                    DecisionTreeClassifier(), DecisionTreeClassifier(),\n",
       "                    DecisionTreeClassifier(), DecisionTreeClassifier(),\n",
       "                    DecisionTreeClassifier(), DecisionTreeClassifier(),\n",
       "                    DecisionTreeClassifier(), DecisionTreeClassifier(),\n",
       "                    DecisionTreeClassifier(), DecisionTreeClassifier(),\n",
       "                    DecisionTreeClassifier(), DecisionTreeClassifier(),\n",
       "                    DecisionTreeClassifier(), DecisionTreeClassifier(),\n",
       "                    DecisionTreeClassifier(), DecisionTreeClassifier()],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_samples': masked_array(data=[0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.9, 0.9, 0.9, 0.9,\n",
       "                    0.9, 0.9],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[10, 10, 50, 50, 100, 100, 10, 10, 50, 50, 100, 100, 10,\n",
       "                    10, 50, 50, 100, 100, 10, 10, 50, 50, 100, 100],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_oob_score': masked_array(data=[True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_random_state': masked_array(data=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                    0, 0, 0, 0, 0, 0],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'estimator': DecisionTreeClassifier(),\n",
       "   'max_samples': 0.3,\n",
       "   'n_estimators': 10,\n",
       "   'oob_score': True,\n",
       "   'random_state': 0},\n",
       "  {'estimator': DecisionTreeClassifier(),\n",
       "   'max_samples': 0.3,\n",
       "   'n_estimators': 10,\n",
       "   'oob_score': False,\n",
       "   'random_state': 0},\n",
       "  {'estimator': DecisionTreeClassifier(),\n",
       "   'max_samples': 0.3,\n",
       "   'n_estimators': 50,\n",
       "   'oob_score': True,\n",
       "   'random_state': 0},\n",
       "  {'estimator': DecisionTreeClassifier(),\n",
       "   'max_samples': 0.3,\n",
       "   'n_estimators': 50,\n",
       "   'oob_score': False,\n",
       "   'random_state': 0},\n",
       "  {'estimator': DecisionTreeClassifier(),\n",
       "   'max_samples': 0.3,\n",
       "   'n_estimators': 100,\n",
       "   'oob_score': True,\n",
       "   'random_state': 0},\n",
       "  {'estimator': DecisionTreeClassifier(),\n",
       "   'max_samples': 0.3,\n",
       "   'n_estimators': 100,\n",
       "   'oob_score': False,\n",
       "   'random_state': 0},\n",
       "  {'estimator': DecisionTreeClassifier(),\n",
       "   'max_samples': 0.5,\n",
       "   'n_estimators': 10,\n",
       "   'oob_score': True,\n",
       "   'random_state': 0},\n",
       "  {'estimator': DecisionTreeClassifier(),\n",
       "   'max_samples': 0.5,\n",
       "   'n_estimators': 10,\n",
       "   'oob_score': False,\n",
       "   'random_state': 0},\n",
       "  {'estimator': DecisionTreeClassifier(),\n",
       "   'max_samples': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'oob_score': True,\n",
       "   'random_state': 0},\n",
       "  {'estimator': DecisionTreeClassifier(),\n",
       "   'max_samples': 0.5,\n",
       "   'n_estimators': 50,\n",
       "   'oob_score': False,\n",
       "   'random_state': 0},\n",
       "  {'estimator': DecisionTreeClassifier(),\n",
       "   'max_samples': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'oob_score': True,\n",
       "   'random_state': 0},\n",
       "  {'estimator': DecisionTreeClassifier(),\n",
       "   'max_samples': 0.5,\n",
       "   'n_estimators': 100,\n",
       "   'oob_score': False,\n",
       "   'random_state': 0},\n",
       "  {'estimator': DecisionTreeClassifier(),\n",
       "   'max_samples': 0.8,\n",
       "   'n_estimators': 10,\n",
       "   'oob_score': True,\n",
       "   'random_state': 0},\n",
       "  {'estimator': DecisionTreeClassifier(),\n",
       "   'max_samples': 0.8,\n",
       "   'n_estimators': 10,\n",
       "   'oob_score': False,\n",
       "   'random_state': 0},\n",
       "  {'estimator': DecisionTreeClassifier(),\n",
       "   'max_samples': 0.8,\n",
       "   'n_estimators': 50,\n",
       "   'oob_score': True,\n",
       "   'random_state': 0},\n",
       "  {'estimator': DecisionTreeClassifier(),\n",
       "   'max_samples': 0.8,\n",
       "   'n_estimators': 50,\n",
       "   'oob_score': False,\n",
       "   'random_state': 0},\n",
       "  {'estimator': DecisionTreeClassifier(),\n",
       "   'max_samples': 0.8,\n",
       "   'n_estimators': 100,\n",
       "   'oob_score': True,\n",
       "   'random_state': 0},\n",
       "  {'estimator': DecisionTreeClassifier(),\n",
       "   'max_samples': 0.8,\n",
       "   'n_estimators': 100,\n",
       "   'oob_score': False,\n",
       "   'random_state': 0},\n",
       "  {'estimator': DecisionTreeClassifier(),\n",
       "   'max_samples': 0.9,\n",
       "   'n_estimators': 10,\n",
       "   'oob_score': True,\n",
       "   'random_state': 0},\n",
       "  {'estimator': DecisionTreeClassifier(),\n",
       "   'max_samples': 0.9,\n",
       "   'n_estimators': 10,\n",
       "   'oob_score': False,\n",
       "   'random_state': 0},\n",
       "  {'estimator': DecisionTreeClassifier(),\n",
       "   'max_samples': 0.9,\n",
       "   'n_estimators': 50,\n",
       "   'oob_score': True,\n",
       "   'random_state': 0},\n",
       "  {'estimator': DecisionTreeClassifier(),\n",
       "   'max_samples': 0.9,\n",
       "   'n_estimators': 50,\n",
       "   'oob_score': False,\n",
       "   'random_state': 0},\n",
       "  {'estimator': DecisionTreeClassifier(),\n",
       "   'max_samples': 0.9,\n",
       "   'n_estimators': 100,\n",
       "   'oob_score': True,\n",
       "   'random_state': 0},\n",
       "  {'estimator': DecisionTreeClassifier(),\n",
       "   'max_samples': 0.9,\n",
       "   'n_estimators': 100,\n",
       "   'oob_score': False,\n",
       "   'random_state': 0}],\n",
       " 'split0_test_score': array([0.70259523, 0.70259523, 0.74382587, 0.74382587, 0.74403516,\n",
       "        0.74403516, 0.70929259, 0.70929259, 0.73922143, 0.73922143,\n",
       "        0.74445375, 0.74445375, 0.70699037, 0.70699037, 0.73482629,\n",
       "        0.73482629, 0.73901214, 0.73901214, 0.70552532, 0.70552532,\n",
       "        0.73377982, 0.73377982, 0.73880285, 0.73880285]),\n",
       " 'split1_test_score': array([0.70866471, 0.70866471, 0.73503558, 0.73503558, 0.74487233,\n",
       "        0.74487233, 0.71159481, 0.71159481, 0.73838426, 0.73838426,\n",
       "        0.73754709, 0.73754709, 0.7118041 , 0.7118041 , 0.73231478,\n",
       "        0.73231478, 0.73817497, 0.73817497, 0.71075764, 0.71075764,\n",
       "        0.73231478, 0.73231478, 0.73922143, 0.73922143]),\n",
       " 'split2_test_score': array([0.70385098, 0.70385098, 0.73691921, 0.73691921, 0.73670992,\n",
       "        0.73670992, 0.7034324 , 0.7034324 , 0.73043114, 0.73043114,\n",
       "        0.73545416, 0.73545416, 0.7005023 , 0.7005023 , 0.73022185,\n",
       "        0.73022185, 0.73629134, 0.73629134, 0.71012976, 0.71012976,\n",
       "        0.73147761, 0.73147761, 0.73105902, 0.73105902]),\n",
       " 'split3_test_score': array([0.704417  , 0.704417  , 0.72911869, 0.72911869, 0.72870002,\n",
       "        0.72870002, 0.70588235, 0.70588235, 0.72702533, 0.72702533,\n",
       "        0.7297467 , 0.7297467 , 0.70190496, 0.70190496, 0.72576931,\n",
       "        0.72576931, 0.72576931, 0.72576931, 0.70253297, 0.70253297,\n",
       "        0.7228386 , 0.7228386 , 0.72095457, 0.72095457]),\n",
       " 'split4_test_score': array([0.70232363, 0.70232363, 0.72849068, 0.72849068, 0.72870002,\n",
       "        0.72870002, 0.6952062 , 0.6952062 , 0.72200126, 0.72200126,\n",
       "        0.72262927, 0.72262927, 0.70190496, 0.70190496, 0.72304794,\n",
       "        0.72304794, 0.72451329, 0.72451329, 0.69646221, 0.69646221,\n",
       "        0.71718652, 0.71718652, 0.72116391, 0.72116391]),\n",
       " 'mean_test_score': array([0.70437031, 0.70437031, 0.73467801, 0.73467801, 0.73660349,\n",
       "        0.73660349, 0.70508167, 0.70508167, 0.73141268, 0.73141268,\n",
       "        0.73396619, 0.73396619, 0.70462134, 0.70462134, 0.72923603,\n",
       "        0.72923603, 0.73275221, 0.73275221, 0.70508158, 0.70508158,\n",
       "        0.72751947, 0.72751947, 0.73024036, 0.73024036]),\n",
       " 'std_test_score': array([0.0022827 , 0.0022827 , 0.0056218 , 0.0056218 , 0.00705045,\n",
       "        0.00705045, 0.00567519, 0.00567519, 0.00660858, 0.00660858,\n",
       "        0.00736689, 0.00736689, 0.0042173 , 0.0042173 , 0.0042898 ,\n",
       "        0.0042898 , 0.00628902, 0.00628902, 0.00526664, 0.00526664,\n",
       "        0.00642704, 0.00642704, 0.00804057, 0.00804057]),\n",
       " 'rank_test_score': array([23, 23,  3,  3,  1,  1, 17, 17,  9,  9,  5,  5, 21, 21, 13, 13,  7,\n",
       "         7, 19, 19, 15, 15, 11, 11])}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "result = GridSearchCV(\n",
    "        BaggingClassifier(),\n",
    "        {\n",
    "            'estimator': [DecisionTreeClassifier()],\n",
    "            'n_estimators': [10, 50, 100],\n",
    "            'max_samples': [0.3, 0.5, 0.8, 0.9],\n",
    "            'oob_score': [True, False],\n",
    "            'random_state': [0]\n",
    "        },\n",
    "    cv=5,\n",
    "    return_train_score=False,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "result.fit(X_valid,Y_valid)\n",
    "result.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09860eb5",
   "metadata": {},
   "source": [
    "# Result for grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3fe8089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_estimator</th>\n",
       "      <th>param_max_samples</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_oob_score</th>\n",
       "      <th>param_random_state</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.678294</td>\n",
       "      <td>0.421788</td>\n",
       "      <td>0.043595</td>\n",
       "      <td>0.004379</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'estimator': DecisionTreeClassifier(), 'max_s...</td>\n",
       "      <td>0.702595</td>\n",
       "      <td>0.708665</td>\n",
       "      <td>0.703851</td>\n",
       "      <td>0.704417</td>\n",
       "      <td>0.702324</td>\n",
       "      <td>0.704370</td>\n",
       "      <td>0.002283</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.254205</td>\n",
       "      <td>0.171900</td>\n",
       "      <td>0.055645</td>\n",
       "      <td>0.020741</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>{'estimator': DecisionTreeClassifier(), 'max_s...</td>\n",
       "      <td>0.702595</td>\n",
       "      <td>0.708665</td>\n",
       "      <td>0.703851</td>\n",
       "      <td>0.704417</td>\n",
       "      <td>0.702324</td>\n",
       "      <td>0.704370</td>\n",
       "      <td>0.002283</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.687846</td>\n",
       "      <td>0.740365</td>\n",
       "      <td>0.229448</td>\n",
       "      <td>0.054316</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.3</td>\n",
       "      <td>50</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'estimator': DecisionTreeClassifier(), 'max_s...</td>\n",
       "      <td>0.743826</td>\n",
       "      <td>0.735036</td>\n",
       "      <td>0.736919</td>\n",
       "      <td>0.729119</td>\n",
       "      <td>0.728491</td>\n",
       "      <td>0.734678</td>\n",
       "      <td>0.005622</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.560612</td>\n",
       "      <td>0.817537</td>\n",
       "      <td>0.185496</td>\n",
       "      <td>0.040543</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.3</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>{'estimator': DecisionTreeClassifier(), 'max_s...</td>\n",
       "      <td>0.743826</td>\n",
       "      <td>0.735036</td>\n",
       "      <td>0.736919</td>\n",
       "      <td>0.729119</td>\n",
       "      <td>0.728491</td>\n",
       "      <td>0.734678</td>\n",
       "      <td>0.005622</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.204088</td>\n",
       "      <td>1.352008</td>\n",
       "      <td>0.306151</td>\n",
       "      <td>0.011551</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.3</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'estimator': DecisionTreeClassifier(), 'max_s...</td>\n",
       "      <td>0.744035</td>\n",
       "      <td>0.744872</td>\n",
       "      <td>0.736710</td>\n",
       "      <td>0.728700</td>\n",
       "      <td>0.728700</td>\n",
       "      <td>0.736603</td>\n",
       "      <td>0.007050</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17.031673</td>\n",
       "      <td>0.633352</td>\n",
       "      <td>0.315785</td>\n",
       "      <td>0.045425</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.3</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>{'estimator': DecisionTreeClassifier(), 'max_s...</td>\n",
       "      <td>0.744035</td>\n",
       "      <td>0.744872</td>\n",
       "      <td>0.736710</td>\n",
       "      <td>0.728700</td>\n",
       "      <td>0.728700</td>\n",
       "      <td>0.736603</td>\n",
       "      <td>0.007050</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.002228</td>\n",
       "      <td>0.241926</td>\n",
       "      <td>0.041123</td>\n",
       "      <td>0.007530</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'estimator': DecisionTreeClassifier(), 'max_s...</td>\n",
       "      <td>0.709293</td>\n",
       "      <td>0.711595</td>\n",
       "      <td>0.703432</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.695206</td>\n",
       "      <td>0.705082</td>\n",
       "      <td>0.005675</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.618584</td>\n",
       "      <td>0.107856</td>\n",
       "      <td>0.041792</td>\n",
       "      <td>0.003356</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>{'estimator': DecisionTreeClassifier(), 'max_s...</td>\n",
       "      <td>0.709293</td>\n",
       "      <td>0.711595</td>\n",
       "      <td>0.703432</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.695206</td>\n",
       "      <td>0.705082</td>\n",
       "      <td>0.005675</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14.162218</td>\n",
       "      <td>1.217511</td>\n",
       "      <td>0.167489</td>\n",
       "      <td>0.015248</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'estimator': DecisionTreeClassifier(), 'max_s...</td>\n",
       "      <td>0.739221</td>\n",
       "      <td>0.738384</td>\n",
       "      <td>0.730431</td>\n",
       "      <td>0.727025</td>\n",
       "      <td>0.722001</td>\n",
       "      <td>0.731413</td>\n",
       "      <td>0.006609</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12.837346</td>\n",
       "      <td>0.766306</td>\n",
       "      <td>0.166234</td>\n",
       "      <td>0.013195</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>{'estimator': DecisionTreeClassifier(), 'max_s...</td>\n",
       "      <td>0.739221</td>\n",
       "      <td>0.738384</td>\n",
       "      <td>0.730431</td>\n",
       "      <td>0.727025</td>\n",
       "      <td>0.722001</td>\n",
       "      <td>0.731413</td>\n",
       "      <td>0.006609</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>27.953118</td>\n",
       "      <td>1.786505</td>\n",
       "      <td>0.376659</td>\n",
       "      <td>0.092058</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'estimator': DecisionTreeClassifier(), 'max_s...</td>\n",
       "      <td>0.744454</td>\n",
       "      <td>0.737547</td>\n",
       "      <td>0.735454</td>\n",
       "      <td>0.729747</td>\n",
       "      <td>0.722629</td>\n",
       "      <td>0.733966</td>\n",
       "      <td>0.007367</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>28.450904</td>\n",
       "      <td>0.904057</td>\n",
       "      <td>0.382949</td>\n",
       "      <td>0.050309</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>{'estimator': DecisionTreeClassifier(), 'max_s...</td>\n",
       "      <td>0.744454</td>\n",
       "      <td>0.737547</td>\n",
       "      <td>0.735454</td>\n",
       "      <td>0.729747</td>\n",
       "      <td>0.722629</td>\n",
       "      <td>0.733966</td>\n",
       "      <td>0.007367</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.605378</td>\n",
       "      <td>0.212470</td>\n",
       "      <td>0.041499</td>\n",
       "      <td>0.008634</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.8</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'estimator': DecisionTreeClassifier(), 'max_s...</td>\n",
       "      <td>0.706990</td>\n",
       "      <td>0.711804</td>\n",
       "      <td>0.700502</td>\n",
       "      <td>0.701905</td>\n",
       "      <td>0.701905</td>\n",
       "      <td>0.704621</td>\n",
       "      <td>0.004217</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.603877</td>\n",
       "      <td>0.189762</td>\n",
       "      <td>0.051485</td>\n",
       "      <td>0.020928</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.8</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>{'estimator': DecisionTreeClassifier(), 'max_s...</td>\n",
       "      <td>0.706990</td>\n",
       "      <td>0.711804</td>\n",
       "      <td>0.700502</td>\n",
       "      <td>0.701905</td>\n",
       "      <td>0.701905</td>\n",
       "      <td>0.704621</td>\n",
       "      <td>0.004217</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>19.721914</td>\n",
       "      <td>1.125734</td>\n",
       "      <td>0.196700</td>\n",
       "      <td>0.042892</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'estimator': DecisionTreeClassifier(), 'max_s...</td>\n",
       "      <td>0.734826</td>\n",
       "      <td>0.732315</td>\n",
       "      <td>0.730222</td>\n",
       "      <td>0.725769</td>\n",
       "      <td>0.723048</td>\n",
       "      <td>0.729236</td>\n",
       "      <td>0.004290</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17.052027</td>\n",
       "      <td>0.257067</td>\n",
       "      <td>0.161719</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>{'estimator': DecisionTreeClassifier(), 'max_s...</td>\n",
       "      <td>0.734826</td>\n",
       "      <td>0.732315</td>\n",
       "      <td>0.730222</td>\n",
       "      <td>0.725769</td>\n",
       "      <td>0.723048</td>\n",
       "      <td>0.729236</td>\n",
       "      <td>0.004290</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>41.830955</td>\n",
       "      <td>2.844125</td>\n",
       "      <td>0.541234</td>\n",
       "      <td>0.099838</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.8</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'estimator': DecisionTreeClassifier(), 'max_s...</td>\n",
       "      <td>0.739012</td>\n",
       "      <td>0.738175</td>\n",
       "      <td>0.736291</td>\n",
       "      <td>0.725769</td>\n",
       "      <td>0.724513</td>\n",
       "      <td>0.732752</td>\n",
       "      <td>0.006289</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>45.268898</td>\n",
       "      <td>2.659552</td>\n",
       "      <td>0.548415</td>\n",
       "      <td>0.184988</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.8</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>{'estimator': DecisionTreeClassifier(), 'max_s...</td>\n",
       "      <td>0.739012</td>\n",
       "      <td>0.738175</td>\n",
       "      <td>0.736291</td>\n",
       "      <td>0.725769</td>\n",
       "      <td>0.724513</td>\n",
       "      <td>0.732752</td>\n",
       "      <td>0.006289</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.788478</td>\n",
       "      <td>0.083267</td>\n",
       "      <td>0.040473</td>\n",
       "      <td>0.002874</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'estimator': DecisionTreeClassifier(), 'max_s...</td>\n",
       "      <td>0.705525</td>\n",
       "      <td>0.710758</td>\n",
       "      <td>0.710130</td>\n",
       "      <td>0.702533</td>\n",
       "      <td>0.696462</td>\n",
       "      <td>0.705082</td>\n",
       "      <td>0.005267</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.049695</td>\n",
       "      <td>0.889790</td>\n",
       "      <td>0.068339</td>\n",
       "      <td>0.021887</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>{'estimator': DecisionTreeClassifier(), 'max_s...</td>\n",
       "      <td>0.705525</td>\n",
       "      <td>0.710758</td>\n",
       "      <td>0.710130</td>\n",
       "      <td>0.702533</td>\n",
       "      <td>0.696462</td>\n",
       "      <td>0.705082</td>\n",
       "      <td>0.005267</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>25.778904</td>\n",
       "      <td>2.854197</td>\n",
       "      <td>0.256812</td>\n",
       "      <td>0.078288</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.9</td>\n",
       "      <td>50</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'estimator': DecisionTreeClassifier(), 'max_s...</td>\n",
       "      <td>0.733780</td>\n",
       "      <td>0.732315</td>\n",
       "      <td>0.731478</td>\n",
       "      <td>0.722839</td>\n",
       "      <td>0.717187</td>\n",
       "      <td>0.727519</td>\n",
       "      <td>0.006427</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>27.324229</td>\n",
       "      <td>1.690987</td>\n",
       "      <td>0.193539</td>\n",
       "      <td>0.032404</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.9</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>{'estimator': DecisionTreeClassifier(), 'max_s...</td>\n",
       "      <td>0.733780</td>\n",
       "      <td>0.732315</td>\n",
       "      <td>0.731478</td>\n",
       "      <td>0.722839</td>\n",
       "      <td>0.717187</td>\n",
       "      <td>0.727519</td>\n",
       "      <td>0.006427</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>44.609385</td>\n",
       "      <td>2.035651</td>\n",
       "      <td>0.283985</td>\n",
       "      <td>0.031533</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.9</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'estimator': DecisionTreeClassifier(), 'max_s...</td>\n",
       "      <td>0.738803</td>\n",
       "      <td>0.739221</td>\n",
       "      <td>0.731059</td>\n",
       "      <td>0.720955</td>\n",
       "      <td>0.721164</td>\n",
       "      <td>0.730240</td>\n",
       "      <td>0.008041</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>36.735086</td>\n",
       "      <td>3.613365</td>\n",
       "      <td>0.173662</td>\n",
       "      <td>0.047081</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.9</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>{'estimator': DecisionTreeClassifier(), 'max_s...</td>\n",
       "      <td>0.738803</td>\n",
       "      <td>0.739221</td>\n",
       "      <td>0.731059</td>\n",
       "      <td>0.720955</td>\n",
       "      <td>0.721164</td>\n",
       "      <td>0.730240</td>\n",
       "      <td>0.008041</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        2.678294      0.421788         0.043595        0.004379   \n",
       "1        2.254205      0.171900         0.055645        0.020741   \n",
       "2       11.687846      0.740365         0.229448        0.054316   \n",
       "3       10.560612      0.817537         0.185496        0.040543   \n",
       "4       20.204088      1.352008         0.306151        0.011551   \n",
       "5       17.031673      0.633352         0.315785        0.045425   \n",
       "6        3.002228      0.241926         0.041123        0.007530   \n",
       "7        2.618584      0.107856         0.041792        0.003356   \n",
       "8       14.162218      1.217511         0.167489        0.015248   \n",
       "9       12.837346      0.766306         0.166234        0.013195   \n",
       "10      27.953118      1.786505         0.376659        0.092058   \n",
       "11      28.450904      0.904057         0.382949        0.050309   \n",
       "12       3.605378      0.212470         0.041499        0.008634   \n",
       "13       3.603877      0.189762         0.051485        0.020928   \n",
       "14      19.721914      1.125734         0.196700        0.042892   \n",
       "15      17.052027      0.257067         0.161719        0.003968   \n",
       "16      41.830955      2.844125         0.541234        0.099838   \n",
       "17      45.268898      2.659552         0.548415        0.184988   \n",
       "18       3.788478      0.083267         0.040473        0.002874   \n",
       "19       5.049695      0.889790         0.068339        0.021887   \n",
       "20      25.778904      2.854197         0.256812        0.078288   \n",
       "21      27.324229      1.690987         0.193539        0.032404   \n",
       "22      44.609385      2.035651         0.283985        0.031533   \n",
       "23      36.735086      3.613365         0.173662        0.047081   \n",
       "\n",
       "             param_estimator param_max_samples param_n_estimators  \\\n",
       "0   DecisionTreeClassifier()               0.3                 10   \n",
       "1   DecisionTreeClassifier()               0.3                 10   \n",
       "2   DecisionTreeClassifier()               0.3                 50   \n",
       "3   DecisionTreeClassifier()               0.3                 50   \n",
       "4   DecisionTreeClassifier()               0.3                100   \n",
       "5   DecisionTreeClassifier()               0.3                100   \n",
       "6   DecisionTreeClassifier()               0.5                 10   \n",
       "7   DecisionTreeClassifier()               0.5                 10   \n",
       "8   DecisionTreeClassifier()               0.5                 50   \n",
       "9   DecisionTreeClassifier()               0.5                 50   \n",
       "10  DecisionTreeClassifier()               0.5                100   \n",
       "11  DecisionTreeClassifier()               0.5                100   \n",
       "12  DecisionTreeClassifier()               0.8                 10   \n",
       "13  DecisionTreeClassifier()               0.8                 10   \n",
       "14  DecisionTreeClassifier()               0.8                 50   \n",
       "15  DecisionTreeClassifier()               0.8                 50   \n",
       "16  DecisionTreeClassifier()               0.8                100   \n",
       "17  DecisionTreeClassifier()               0.8                100   \n",
       "18  DecisionTreeClassifier()               0.9                 10   \n",
       "19  DecisionTreeClassifier()               0.9                 10   \n",
       "20  DecisionTreeClassifier()               0.9                 50   \n",
       "21  DecisionTreeClassifier()               0.9                 50   \n",
       "22  DecisionTreeClassifier()               0.9                100   \n",
       "23  DecisionTreeClassifier()               0.9                100   \n",
       "\n",
       "   param_oob_score param_random_state  \\\n",
       "0             True                  0   \n",
       "1            False                  0   \n",
       "2             True                  0   \n",
       "3            False                  0   \n",
       "4             True                  0   \n",
       "5            False                  0   \n",
       "6             True                  0   \n",
       "7            False                  0   \n",
       "8             True                  0   \n",
       "9            False                  0   \n",
       "10            True                  0   \n",
       "11           False                  0   \n",
       "12            True                  0   \n",
       "13           False                  0   \n",
       "14            True                  0   \n",
       "15           False                  0   \n",
       "16            True                  0   \n",
       "17           False                  0   \n",
       "18            True                  0   \n",
       "19           False                  0   \n",
       "20            True                  0   \n",
       "21           False                  0   \n",
       "22            True                  0   \n",
       "23           False                  0   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'estimator': DecisionTreeClassifier(), 'max_s...           0.702595   \n",
       "1   {'estimator': DecisionTreeClassifier(), 'max_s...           0.702595   \n",
       "2   {'estimator': DecisionTreeClassifier(), 'max_s...           0.743826   \n",
       "3   {'estimator': DecisionTreeClassifier(), 'max_s...           0.743826   \n",
       "4   {'estimator': DecisionTreeClassifier(), 'max_s...           0.744035   \n",
       "5   {'estimator': DecisionTreeClassifier(), 'max_s...           0.744035   \n",
       "6   {'estimator': DecisionTreeClassifier(), 'max_s...           0.709293   \n",
       "7   {'estimator': DecisionTreeClassifier(), 'max_s...           0.709293   \n",
       "8   {'estimator': DecisionTreeClassifier(), 'max_s...           0.739221   \n",
       "9   {'estimator': DecisionTreeClassifier(), 'max_s...           0.739221   \n",
       "10  {'estimator': DecisionTreeClassifier(), 'max_s...           0.744454   \n",
       "11  {'estimator': DecisionTreeClassifier(), 'max_s...           0.744454   \n",
       "12  {'estimator': DecisionTreeClassifier(), 'max_s...           0.706990   \n",
       "13  {'estimator': DecisionTreeClassifier(), 'max_s...           0.706990   \n",
       "14  {'estimator': DecisionTreeClassifier(), 'max_s...           0.734826   \n",
       "15  {'estimator': DecisionTreeClassifier(), 'max_s...           0.734826   \n",
       "16  {'estimator': DecisionTreeClassifier(), 'max_s...           0.739012   \n",
       "17  {'estimator': DecisionTreeClassifier(), 'max_s...           0.739012   \n",
       "18  {'estimator': DecisionTreeClassifier(), 'max_s...           0.705525   \n",
       "19  {'estimator': DecisionTreeClassifier(), 'max_s...           0.705525   \n",
       "20  {'estimator': DecisionTreeClassifier(), 'max_s...           0.733780   \n",
       "21  {'estimator': DecisionTreeClassifier(), 'max_s...           0.733780   \n",
       "22  {'estimator': DecisionTreeClassifier(), 'max_s...           0.738803   \n",
       "23  {'estimator': DecisionTreeClassifier(), 'max_s...           0.738803   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.708665           0.703851           0.704417   \n",
       "1            0.708665           0.703851           0.704417   \n",
       "2            0.735036           0.736919           0.729119   \n",
       "3            0.735036           0.736919           0.729119   \n",
       "4            0.744872           0.736710           0.728700   \n",
       "5            0.744872           0.736710           0.728700   \n",
       "6            0.711595           0.703432           0.705882   \n",
       "7            0.711595           0.703432           0.705882   \n",
       "8            0.738384           0.730431           0.727025   \n",
       "9            0.738384           0.730431           0.727025   \n",
       "10           0.737547           0.735454           0.729747   \n",
       "11           0.737547           0.735454           0.729747   \n",
       "12           0.711804           0.700502           0.701905   \n",
       "13           0.711804           0.700502           0.701905   \n",
       "14           0.732315           0.730222           0.725769   \n",
       "15           0.732315           0.730222           0.725769   \n",
       "16           0.738175           0.736291           0.725769   \n",
       "17           0.738175           0.736291           0.725769   \n",
       "18           0.710758           0.710130           0.702533   \n",
       "19           0.710758           0.710130           0.702533   \n",
       "20           0.732315           0.731478           0.722839   \n",
       "21           0.732315           0.731478           0.722839   \n",
       "22           0.739221           0.731059           0.720955   \n",
       "23           0.739221           0.731059           0.720955   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.702324         0.704370        0.002283               23  \n",
       "1            0.702324         0.704370        0.002283               23  \n",
       "2            0.728491         0.734678        0.005622                3  \n",
       "3            0.728491         0.734678        0.005622                3  \n",
       "4            0.728700         0.736603        0.007050                1  \n",
       "5            0.728700         0.736603        0.007050                1  \n",
       "6            0.695206         0.705082        0.005675               17  \n",
       "7            0.695206         0.705082        0.005675               17  \n",
       "8            0.722001         0.731413        0.006609                9  \n",
       "9            0.722001         0.731413        0.006609                9  \n",
       "10           0.722629         0.733966        0.007367                5  \n",
       "11           0.722629         0.733966        0.007367                5  \n",
       "12           0.701905         0.704621        0.004217               21  \n",
       "13           0.701905         0.704621        0.004217               21  \n",
       "14           0.723048         0.729236        0.004290               13  \n",
       "15           0.723048         0.729236        0.004290               13  \n",
       "16           0.724513         0.732752        0.006289                7  \n",
       "17           0.724513         0.732752        0.006289                7  \n",
       "18           0.696462         0.705082        0.005267               19  \n",
       "19           0.696462         0.705082        0.005267               19  \n",
       "20           0.717187         0.727519        0.006427               15  \n",
       "21           0.717187         0.727519        0.006427               15  \n",
       "22           0.721164         0.730240        0.008041               11  \n",
       "23           0.721164         0.730240        0.008041               11  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(result.cv_results_)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356d08be",
   "metadata": {},
   "source": [
    "<h3>get the best parameters for model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cef830",
   "metadata": {},
   "outputs": [],
   "source": [
    "df [['param_n_estimators','params','mean_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dba70d2",
   "metadata": {},
   "source": [
    "<h3>Random GridSearch for Bagging</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee728ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "result = RandomizedSearchCV(\n",
    "        BaggingClassifier(),\n",
    "        {\n",
    "            'estimator': [DecisionTreeClassifier()],\n",
    "            'n_estimators': [10, 50, 100],\n",
    "            'max_samples': [0.3, 0.5, 0.8, 0.9],\n",
    "            'oob_score': [True, False],\n",
    "            'random_state': [0]\n",
    "        },\n",
    "    cv=5,\n",
    "    return_train_score=False,\n",
    "    n_iter = 5, #number of random combinations of hyperparameters that will be tried\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "result.fit(X_valid,Y_valid)\n",
    "pd.DataFrame(result.cv_results_)[['param_n_estimators','params','mean_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce28993",
   "metadata": {},
   "source": [
    "<h3>GRIDSERACH FOR RandomForestClassifier</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4128e730",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "result = GridSearchCV(\n",
    "    RandomForestClassifier(), {\n",
    "         'n_estimators': [100,200,300]\n",
    "    },\n",
    "    cv = 5,return_train_score = False,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "result.fit(X_valid,Y_valid)\n",
    "result.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e58b461",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(result.cv_results_)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09f1679",
   "metadata": {},
   "source": [
    "<h3>picking columns from tables to see score</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2556f769",
   "metadata": {},
   "outputs": [],
   "source": [
    "df [['param_n_estimators','params','mean_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6bddf0",
   "metadata": {},
   "source": [
    "<h2>getting best score</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8e2329",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e889f1",
   "metadata": {},
   "source": [
    "<h3>getting best parameters</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556a6095",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187259f9",
   "metadata": {},
   "source": [
    "<h2>RANDOMIZED GridSearch</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "154621e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:307: UserWarning: The total space of parameters 3 is smaller than n_iter=5. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7460649698593436\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "result = RandomizedSearchCV(\n",
    "        estimator=RandomForestClassifier()\n",
    "        {\n",
    "            'n_estimators': [100,200,300]\n",
    "        },\n",
    "        cv=5,\n",
    "        return_train_score = False,\n",
    "        n_iter = 5,\n",
    "        n_jobs=-1\n",
    "    \n",
    ")\n",
    "\n",
    "result.fit(X_valid, Y_valid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b508d51",
   "metadata": {},
   "source": [
    "<h4>getting best parameters and score(accuracy)</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb050801",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(result.cv_results_)[['param_n_estimators','params','mean_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128f0f98",
   "metadata": {},
   "source": [
    "<h2>Grid search for AdaBoost</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17077454",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "result = GridSearchCV(\n",
    "    AdaBoostClassifier(),\n",
    "    {\n",
    "        'n_estimators': [100,200,300],\n",
    "        'learning_rate': [1,0.1,0.3]\n",
    "    },\n",
    "    cv=5,\n",
    "    return_train_score = False,\n",
    "    n_jobs=-1\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "result.fit(X_valid,Y_valid)\n",
    "result.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed4d68d",
   "metadata": {},
   "source": [
    "<h4>getting best parameters and score(accuracy)</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a736a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(result.cv_results_)[['param_n_estimators','params','mean_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0aa512",
   "metadata": {},
   "source": [
    "<h2>getting best score</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eb6c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a129d343",
   "metadata": {},
   "source": [
    "<h3>getting best parameters</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be456cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a25d2d9",
   "metadata": {},
   "source": [
    "<h2>Randomized Grid search for AdaBoost</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27288fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "result = RandomizedSearchCV(\n",
    "    AdaBoostClassifier(),\n",
    "    {\n",
    "        'n_estimators': [100,200,300],\n",
    "        'learning_rate': [1,0.1,0.3]\n",
    "    },\n",
    "    cv=5,\n",
    "    return_train_score = False,\n",
    "    n_iter = 5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "result.fit(X_valid,Y_valid)\n",
    "result.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c3b977",
   "metadata": {},
   "source": [
    "<h4>getting best parameters and score(accuracy)</h4>\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773d97ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(result.cv_results_)[['param_n_estimators','params','mean_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbafb346",
   "metadata": {},
   "source": [
    "<h2>getting best score</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0356fb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31683f6",
   "metadata": {},
   "source": [
    "<h3>getting best parameters</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eba9ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
