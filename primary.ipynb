{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "470a814c",
   "metadata": {},
   "source": [
    "<h3>importing libraries</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17c5165a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8001de60",
   "metadata": {},
   "source": [
    "<h5>read data and explore it </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "631b5108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159256 entries, 0 to 159255\n",
      "Data columns (total 11 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   eyesight(left)    159256 non-null  float64\n",
      " 1   systolic          159256 non-null  int64  \n",
      " 2   serum creatinine  159256 non-null  float64\n",
      " 3   triglyceride      159256 non-null  int64  \n",
      " 4   Cholesterol       159256 non-null  int64  \n",
      " 5   AST               159256 non-null  int64  \n",
      " 6   height(cm)        159256 non-null  int64  \n",
      " 7   waist(cm)         159256 non-null  float64\n",
      " 8   age               159256 non-null  int64  \n",
      " 9   LDL               159256 non-null  int64  \n",
      " 10  smoking           159256 non-null  int64  \n",
      "dtypes: float64(3), int64(8)\n",
      "memory usage: 13.4 MB\n",
      "eyesight(left)      0\n",
      "systolic            0\n",
      "serum creatinine    0\n",
      "triglyceride        0\n",
      "Cholesterol         0\n",
      "AST                 0\n",
      "height(cm)          0\n",
      "waist(cm)           0\n",
      "age                 0\n",
      "LDL                 0\n",
      "smoking             0\n",
      "dtype: int64\n",
      "(159256, 11)\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(\"Your_data.csv\")\n",
    "data.drop(data.columns[0], axis=1,inplace=True)\n",
    "data.head(3)\n",
    "data.info()\n",
    "print(str(data.isnull().sum()))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87741e5",
   "metadata": {},
   "source": [
    "<h4> data split in train , test and validataion</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2465dc42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159256, 11)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X=data.drop('smoking', axis=1)\n",
    "Y = data['smoking']\n",
    "train_data, test_data = train_test_split(data, test_size=0.3, random_state=42, stratify=data['smoking'])\n",
    "X_train=train_data.drop(['smoking'],axis=1)\n",
    "Y_train=train_data['smoking']\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca4c7ff",
   "metadata": {},
   "source": [
    "<h3> remove outliers from train data by percentile</h3>\n",
    "<p> test age feature</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58cc3ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.0 20.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_threshold=train_data['age'].quantile(1)\n",
    "min_threshold=train_data['age'].quantile(0)\n",
    "print(max_threshold,min_threshold)\n",
    "#all ages are possible ages of smokers won't remove any"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d7e5f1",
   "metadata": {},
   "source": [
    "<p> test LDL feature</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73ccf0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202.0 42.0\n",
      "(111249, 11)\n"
     ]
    }
   ],
   "source": [
    "max_threshold = train_data['LDL'].quantile(0.999)\n",
    "min_threshold = train_data['LDL'].quantile(0.001)\n",
    "print(max_threshold,min_threshold)\n",
    "train_data = train_data[(train_data['LDL'] < max_threshold) & (train_data['LDL'] > min_threshold)]\n",
    "\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecdbc7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test AST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37841f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187.87679999995453 9.0\n",
      "(111221, 11)\n"
     ]
    }
   ],
   "source": [
    "max_threshold = train_data['AST'].quantile(0.9999)\n",
    "min_threshold = train_data['AST'].quantile(0.0001)\n",
    "print(max_threshold,min_threshold)\n",
    "train_data = train_data[(train_data['AST'] < max_threshold) & (train_data['AST'] > min_threshold)]\n",
    "\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c734284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.987799999998242 0.1122\n",
      "(111197, 11)\n"
     ]
    }
   ],
   "source": [
    "max_threshold = train_data['serum creatinine'].quantile(0.9999)\n",
    "min_threshold = train_data['serum creatinine'].quantile(0.0001)\n",
    "print(max_threshold,min_threshold)\n",
    "train_data = train_data[(train_data['serum creatinine'] < max_threshold) & (train_data['serum creatinine'] > min_threshold)]\n",
    "\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2543cb73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30fa59e6",
   "metadata": {},
   "source": [
    "<p> test chelosterol feature</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "011f5275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283.0 118.0\n",
      "(110963, 11)\n"
     ]
    }
   ],
   "source": [
    "max_threshold = train_data['Cholesterol'].quantile(0.999)\n",
    "min_threshold = train_data['Cholesterol'].quantile(0.001)\n",
    "print(max_threshold,min_threshold)\n",
    "train_data = train_data[(train_data['Cholesterol'] < max_threshold) & (train_data['Cholesterol'] > min_threshold)]\n",
    "\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61323198",
   "metadata": {},
   "source": [
    "<p>test systolic feature</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea6729d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170.0 90.0\n",
      "(110300, 11)\n"
     ]
    }
   ],
   "source": [
    "max_threshold = train_data['systolic'].quantile(0.999)\n",
    "min_threshold = train_data['systolic'].quantile(0.001)\n",
    "print(max_threshold,min_threshold)\n",
    "train_data = train_data[(train_data['systolic'] < max_threshold) & (train_data['systolic'] > min_threshold)]\n",
    "\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6ad985",
   "metadata": {},
   "source": [
    "test height feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9976329d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185.0 140.0\n",
      "(108906, 11)\n"
     ]
    }
   ],
   "source": [
    "max_threshold = train_data['height(cm)'].quantile(0.999)\n",
    "min_threshold = train_data['height(cm)'].quantile(0.001)\n",
    "print(max_threshold,min_threshold)\n",
    "train_data = train_data[(train_data['height(cm)'] < max_threshold) & (train_data['height(cm)'] > min_threshold)]\n",
    "\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f691f4b",
   "metadata": {},
   "source": [
    "<h3>z score normalization to remove outliers</h3>\n",
    "<p>  is suited for triglyceride distribution</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6a5709a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(107774, 11)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "z_scores = zscore(train_data['triglyceride'])\n",
    "z_score_threshold = 3\n",
    "outliers = np.abs(z_scores) > z_score_threshold\n",
    "\n",
    "train_data = train_data[~outliers]\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "339dc57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(107494, 11)\n"
     ]
    }
   ],
   "source": [
    "#waist\n",
    "z_scores = zscore(train_data['waist(cm)'])\n",
    "z_score_threshold = 3\n",
    "outliers = np.abs(z_scores) > z_score_threshold\n",
    "\n",
    "train_data = train_data[~outliers]\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "862729df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(107401, 11)\n"
     ]
    }
   ],
   "source": [
    "#eyesight(left)\n",
    "z_scores = zscore(train_data['eyesight(left)'])\n",
    "z_score_threshold = 3\n",
    "outliers = np.abs(z_scores) > z_score_threshold\n",
    "\n",
    "train_data = train_data[~outliers]\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a36471",
   "metadata": {},
   "source": [
    "<h3>splitting train,test,validate data into x and y </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e30e30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train=train_data.drop(['smoking'],axis=1)\n",
    "Y_train=train_data['smoking']\n",
    "validation,test=train_test_split(test_data, test_size=0.5, random_state=42, stratify=test_data['smoking'])\n",
    "X_valid=validation.drop(['smoking'],axis=1)\n",
    "Y_valid=validation['smoking']\n",
    "X_test=test.drop(['smoking'],axis=1)\n",
    "Y_test=test['smoking']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70485b7d",
   "metadata": {},
   "source": [
    "<h3>data normalization</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50faccd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(131290, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(131290,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizer=StandardScaler()\n",
    "X_train=normalizer.fit_transform(X_train)\n",
    "X_test = normalizer.transform(X_test)\n",
    "X_valid=normalizer.transform(X_valid)\n",
    "X = np.vstack((X_train, X_test))\n",
    "print(X.shape)\n",
    "Y = np.concatenate((Y_train.values, Y_test.values))\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "098e843b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smoking\n",
       "0    60866\n",
       "1    46535\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b78cb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train using stand alone model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce03ffc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.66931983, 0.66524488, 0.66893899, 0.66551146, 0.66684439])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "scores = cross_val_score(DecisionTreeClassifier(), X, Y, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94948fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6671719095132913"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc533b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train using Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "647a760a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7396672284243163"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bag_model = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(), \n",
    "    n_estimators=100, \n",
    "    max_samples=0.8, \n",
    "    oob_score=True,\n",
    "    random_state=0\n",
    ")\n",
    "bag_model.fit(X_train, Y_train)\n",
    "bag_model.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85adfddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7396182183523108"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_model.score(X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed655bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score= 0.7398255137289225\n",
      "validation score= 0.7390321500334897\n"
     ]
    }
   ],
   "source": [
    "#try to drop serum ceratine feature because it has low variance\n",
    "X_train=train_data.drop(['serum creatinine'],axis=1)\n",
    "X_train=train_data.drop(['smoking'],axis=1)\n",
    "X_valid=validation.drop(['serum creatinine'],axis=1)\n",
    "X_valid=validation.drop(['smoking'],axis=1)\n",
    "bag_model = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(), \n",
    "    n_estimators=100, \n",
    "    max_samples=0.8, \n",
    "    oob_score=True,\n",
    "    random_state=0\n",
    ")\n",
    "bag_model.fit(X_train, Y_train)\n",
    "print(\"train score= \"+str(bag_model.oob_score_))\n",
    "print(\"validation score= \"+str(bag_model.score(X_valid, Y_valid)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e17c0d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score= 0.7398255137289225\n",
      "validation score= 0.7390321500334897\n"
     ]
    }
   ],
   "source": [
    "#try to drop LDL because it has high correlation with chelosterol\n",
    "X_train=train_data.drop(['LDL'],axis=1)\n",
    "X_train=train_data.drop(['smoking'],axis=1)\n",
    "X_valid=validation.drop(['LDL'],axis=1)\n",
    "X_valid=validation.drop(['smoking'],axis=1)\n",
    "bag_model1 = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(), \n",
    "    n_estimators=100, \n",
    "    max_samples=0.8, \n",
    "    oob_score=True,\n",
    "    random_state=0\n",
    ")\n",
    "bag_model1.fit(X_train, Y_train)\n",
    "print(\"train score= \"+str(bag_model1.oob_score_))\n",
    "print(\"validation score= \"+str(bag_model1.score(X_valid, Y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14ff91db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score= 0.7395741194216069\n",
      "validation score= 0.737399531145345\n"
     ]
    }
   ],
   "source": [
    "train_data['sysheight']=train_data['systolic']*train_data['height(cm)']\n",
    "validation['sysheight']=validation['systolic']*validation['height(cm)']\n",
    "X_train=train_data.drop(['smoking'],axis=1)\n",
    "X_valid=validation.drop(['smoking'],axis=1)\n",
    "bag_model2 = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(), \n",
    "    n_estimators=100, \n",
    "    max_samples=0.8, \n",
    "    oob_score=True,\n",
    "    random_state=0\n",
    ")\n",
    "bag_model2.fit(X_train, Y_train)\n",
    "print(\"train score= \"+str(bag_model2.oob_score_))\n",
    "print(\"validation score= \"+str(bag_model2.score(X_valid, Y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef285fab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "056ea41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 1 : 0.740162424648359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 2 : 0.7094775619557937\n"
     ]
    }
   ],
   "source": [
    "X_train=train_data.drop(['smoking'],axis=1)\n",
    "X_valid=validation.drop(['smoking'],axis=1)\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import metrics\n",
    "Adamodel = AdaBoostClassifier(n_estimators=100 ,learning_rate=1)\n",
    "model = Adamodel.fit(X_train,Y_train)\n",
    "y_pred = model.predict(X_valid)\n",
    "print(\"Accuracy 1 :\",metrics.accuracy_score(Y_valid,y_pred)) \n",
    "# -----------------------------------------------------------\n",
    "# using logisticRegression \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "logisticModel = LogisticRegression()\n",
    "Adamodel_2 = AdaBoostClassifier(n_estimators=50 ,base_estimator=logisticModel,learning_rate=1)\n",
    "model_2 = Adamodel_2.fit(X_train,Y_train)\n",
    "y_pred_2 = model_2.predict(X_valid)\n",
    "print(\"Accuracy 2 :\",metrics.accuracy_score(Y_valid,y_pred_2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "56c9c8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 10 features, but AdaBoostClassifier is expecting 11 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m Adamodel \u001b[38;5;241m=\u001b[39m AdaBoostClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m ,learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m Adamodel\u001b[38;5;241m.\u001b[39mfit(X_train,Y_train)\n\u001b[1;32m---> 10\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy 1 :\u001b[39m\u001b[38;5;124m\"\u001b[39m,metrics\u001b[38;5;241m.\u001b[39maccuracy_score(Y_test,y_pred)) \n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# -----------------------------------------------------------\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# using logisticRegression \u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:710\u001b[0m, in \u001b[0;36mAdaBoostClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    693\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    694\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Predict classes for X.\u001b[39;00m\n\u001b[0;32m    695\u001b[0m \n\u001b[0;32m    696\u001b[0m \u001b[38;5;124;03m    The predicted class of an input sample is computed as the weighted mean\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    708\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 710\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X)\n\u001b[0;32m    712\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    713\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(pred \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32md:\\anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:771\u001b[0m, in \u001b[0;36mAdaBoostClassifier.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    752\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute the decision function of ``X``.\u001b[39;00m\n\u001b[0;32m    753\u001b[0m \n\u001b[0;32m    754\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    768\u001b[0m \u001b[38;5;124;03m    class in ``classes_``, respectively.\u001b[39;00m\n\u001b[0;32m    769\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    770\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 771\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X(X)\n\u001b[0;32m    773\u001b[0m n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_\n\u001b[0;32m    774\u001b[0m classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[:, np\u001b[38;5;241m.\u001b[39mnewaxis]\n",
      "File \u001b[1;32md:\\anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:101\u001b[0m, in \u001b[0;36mBaseWeightBoosting._check_X\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_X\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;66;03m# Only called to validate X in non-fit methods, therefore reset=False\u001b[39;00m\n\u001b[1;32m--> 101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    102\u001b[0m         X,\n\u001b[0;32m    103\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    104\u001b[0m         ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    105\u001b[0m         allow_nd\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    106\u001b[0m         dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    107\u001b[0m         reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    108\u001b[0m     )\n",
      "File \u001b[1;32md:\\anaconda\\Lib\\site-packages\\sklearn\\base.py:625\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    622\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 625\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32md:\\anaconda\\Lib\\site-packages\\sklearn\\base.py:414\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    416\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    417\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 10 features, but AdaBoostClassifier is expecting 11 features as input."
     ]
    }
   ],
   "source": [
    "#try to drop serum ceratine feature because it has low variance\n",
    "X_train=train_data.drop(['serum creatinine'],axis=1)\n",
    "X_train=train_data.drop(['smoking'],axis=1)\n",
    "X_valid=validation.drop(['serum creatinine'],axis=1)\n",
    "X_valid=validation.drop(['smoking'],axis=1)\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import metrics\n",
    "Adamodel = AdaBoostClassifier(n_estimators=100 ,learning_rate=1)\n",
    "model = Adamodel.fit(X_train,Y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy 1 :\",metrics.accuracy_score(Y_test,y_pred)) \n",
    "# -----------------------------------------------------------\n",
    "# using logisticRegression \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "logisticModel = LogisticRegression()\n",
    "Adamodel_2 = AdaBoostClassifier(n_estimators=50 ,base_estimator=logisticModel,learning_rate=1)\n",
    "model_2 = Adamodel_2.fit(X_train,Y_train)\n",
    "y_pred_2 = model_2.predict(X_test)\n",
    "print(\"Accuracy 2 :\",metrics.accuracy_score(Y_test,y_pred_2)) \n",
    "# ada boast model needs the features with low variation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84390797",
   "metadata": {},
   "source": [
    "# Train using Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c00e1284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  : 0.7415020093770931\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "randomForest = RandomForestClassifier(n_estimators= 100)\n",
    "randomForestModel = randomForest.fit(X_train,Y_train)\n",
    "y_pred_0 = randomForestModel.predict(X_valid)\n",
    "# randomForestModel.oob_score_\n",
    "print(\"Accuracy  :\",metrics.accuracy_score(Y_valid,y_pred_0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f1819df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  : 0.743009042196919\n"
     ]
    }
   ],
   "source": [
    "# try adding another feature to random forest model\n",
    "train_data['sysheight']=train_data['systolic']*train_data['height(cm)']\n",
    "validation['sysheight']=validation['systolic']*validation['height(cm)']\n",
    "X_train=train_data.drop(['smoking'],axis=1)\n",
    "X_valid=validation.drop(['smoking'],axis=1)\n",
    "randomForest = RandomForestClassifier(n_estimators= 100)\n",
    "randomForestModel = randomForest.fit(X_train,Y_train)\n",
    "y_pred_0 = randomForestModel.predict(X_valid)\n",
    "# randomForestModel.oob_score_\n",
    "print(\"Accuracy  :\",metrics.accuracy_score(Y_valid,y_pred_0)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d11aaf",
   "metadata": {},
   "source": [
    "<h1>GRIDSEARCH</h1>\n",
    "<h3>GRIDSERACH FOR BaggingClassifier</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131a163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "result = GridSearchCV(\n",
    "        BaggingClassifier(),\n",
    "        {\n",
    "            'estimator': [DecisionTreeClassifier()],\n",
    "            'n_estimators': [10, 50, 100],\n",
    "            'max_samples': [0.3, 0.5, 0.8, 0.9],\n",
    "            'oob_score': [True, False],\n",
    "            'random_state': [0]\n",
    "        },\n",
    "    cv=5,\n",
    "    return_train_score=False,\n",
    ")\n",
    "\n",
    "result.fit(X_train,Y_train)\n",
    "result.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09860eb5",
   "metadata": {},
   "source": [
    "# Result for grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fe8089",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(result.cv_results_)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356d08be",
   "metadata": {},
   "source": [
    "<h3>get the best parameters for model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cef830",
   "metadata": {},
   "outputs": [],
   "source": [
    "df [['param_n_estimators','params','mean_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dba70d2",
   "metadata": {},
   "source": [
    "<h3>Random GridSearch for Bagging</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee728ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "result = RandomizedSearchCV(\n",
    "        BaggingClassifier(),\n",
    "        {\n",
    "            'estimator': [DecisionTreeClassifier()],\n",
    "            'n_estimators': [10, 50, 100],\n",
    "            'max_samples': [0.3, 0.5, 0.8, 0.9],\n",
    "            'oob_score': [True, False],\n",
    "            'random_state': [0]\n",
    "        },\n",
    "    cv=5,\n",
    "    return_train_score=False,\n",
    "    n_iter = 5 #number of random combinations of hyperparameters that will be tried\n",
    ")\n",
    "\n",
    "result.fit(X,y)\n",
    "pd.DataFrame(result.cv_results_)[['param_n_estimators','params','mean_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce28993",
   "metadata": {},
   "source": [
    "<h3>GRIDSERACH FOR RandomForestClassifier</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4128e730",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "result = GridSearchCV(\n",
    "    RandomForestClassifier(), {\n",
    "         'n_estimators': [100,200,300]\n",
    "    },\n",
    "    cv = 5,return_train_score = False,\n",
    ")\n",
    "\n",
    "result.fit(X_train,Y_train)\n",
    "result.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e58b461",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(result.cv_results_)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09f1679",
   "metadata": {},
   "source": [
    "<h3>picking columns from tables to see score</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2556f769",
   "metadata": {},
   "outputs": [],
   "source": [
    "df [['param_n_estimators','params','mean_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6bddf0",
   "metadata": {},
   "source": [
    "<h2>getting best score</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8e2329",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e889f1",
   "metadata": {},
   "source": [
    "<h3>getting best parameters</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556a6095",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187259f9",
   "metadata": {},
   "source": [
    "<h2>RANDOMIZED GridSearch</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "154621e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:307: UserWarning: The total space of parameters 3 is smaller than n_iter=5. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7460649698593436\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "result = RandomizedSearchCV(\n",
    "        estimator=RandomForestClassifier(),\n",
    "        {\n",
    "            'n_estimators': [100,200,300]\n",
    "        },\n",
    "        cv=5,\n",
    "        return_train_score = False,\n",
    "        n_iter = 5\n",
    "    \n",
    ")\n",
    "\n",
    "result.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b508d51",
   "metadata": {},
   "source": [
    "<h4>getting best parameters and score(accuracy)</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb050801",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(result.cv_results_)[['param_n_estimators','params','mean_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128f0f98",
   "metadata": {},
   "source": [
    "<h2>Grid search for AdaBoost</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17077454",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "result = GridSearchCV(\n",
    "    AdaBoostClassifier(),\n",
    "    {\n",
    "        'n_estimators': [100,200,300],\n",
    "        'learning_rate': [1,0.1,0.3]\n",
    "    },\n",
    "    cv=5,\n",
    "    return_train_score = False,\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "result.fit(X_train,Y_train)\n",
    "result.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed4d68d",
   "metadata": {},
   "source": [
    "<h4>getting best parameters and score(accuracy)</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a736a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(result.cv_results_)[['param_n_estimators','params','mean_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0aa512",
   "metadata": {},
   "source": [
    "<h2>getting best score</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eb6c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a129d343",
   "metadata": {},
   "source": [
    "<h3>getting best parameters</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be456cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a25d2d9",
   "metadata": {},
   "source": [
    "<h2>Randomized Grid search for AdaBoost</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27288fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "result = RandomizedSearchCV(\n",
    "    AdaBoostClassifier(),\n",
    "    {\n",
    "        'n_estimators': [100,200,300],\n",
    "        'learning_rate': [1,0.1,0.3]\n",
    "    },\n",
    "    cv=5,\n",
    "    return_train_score = False,\n",
    "    n_iter = 5\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "result.fit(X_train,Y_train)\n",
    "result.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c3b977",
   "metadata": {},
   "source": [
    "<h4>getting best parameters and score(accuracy)</h4>\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773d97ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(result.cv_results_)[['param_n_estimators','params','mean_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbafb346",
   "metadata": {},
   "source": [
    "<h2>getting best score</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0356fb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31683f6",
   "metadata": {},
   "source": [
    "<h3>getting best parameters</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eba9ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
